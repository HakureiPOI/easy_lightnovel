{"cells":[{"cell_type":"markdown","metadata":{"id":"96na5sRTWm1a"},"source":["### 开发者笔记\n","作者：***HakureiPOI***\n","\n","最后更新：2024/8/19\n","\n","功能：根据关键词对ESJ轻小说进行下载\n","\n","待实现功能：一大堆\n","\n","使用手册：见实例化部分\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"2S_GYBtxKapL"},"source":["### 准备工作"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3917,"status":"ok","timestamp":1724045884643,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"iC6MLoqBA35w","outputId":"2a29baf4-8f38-4f2a-ccaa-d18c4f5f24d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencc in /usr/local/lib/python3.10/dist-packages (1.1.9)\n"]}],"source":["!pip install opencc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nih49frsKryJ"},"outputs":[],"source":["import pandas as pd\n","import requests\n","import logging\n","import json\n","import time\n","import os\n","import sys\n","import re\n","import bs4\n","import pickle\n","from opencc import OpenCC\n","from bs4 import BeautifulSoup\n","from concurrent.futures import ThreadPoolExecutor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNl_-o5XbDhA"},"outputs":[],"source":["os.makedirs('logs', exist_ok = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2eUZS9FcICG"},"outputs":[],"source":["logger = logging.getLogger(__name__)\n","logger.setLevel(logging.DEBUG)\n","\n","formatter = logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')\n","\n","streamHandler = logging.StreamHandler()\n","streamHandler.setFormatter(formatter)\n","logger.addHandler(streamHandler)\n","\n","fileHandler = logging.FileHandler('logs/log.txt')\n","fileHandler.setFormatter(formatter)\n","logger.addHandler(fileHandler)"]},{"cell_type":"markdown","metadata":{"id":"RTN2GVFocTSm"},"source":["---\n","### 轻小说爬虫类\n","\n","以后应该都会按照这个模板来实现"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClWjE8dCcLEF"},"outputs":[],"source":["class AbstractScraper():\n","    def __init__(self, usr, pwd, domain_name, path):\n","        self.usr = usr\n","        self.pwd = pwd\n","        self.domain_name = domain_name\n","        self.path = path\n","        self.api = Interface(usr, pwd, domain_name)\n","        self.keyword = ''\n","        self.novels = []\n","        self.simplify = False\n","        self.login()\n","    def login(self):\n","        pass\n","    def search(self):\n","        pass\n","    def print_novels(self):\n","        pass\n","    def set_keyword(self, keyword):\n","        pass\n","    def set_simplify(self):\n","        pass\n","    def get_web_novels(self):\n","        pass\n","    def get_local_novels(self):\n","        pass\n","    def update_novels(self):\n","        pass\n","    def download_novels(self):\n","        pass\n","    def save_novels(self):\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWmi85wryMEO"},"outputs":[],"source":["class Scraper(AbstractScraper):\n","    def __init__(self, usr, pwd, domain_name, path):\n","        super().__init__(usr, pwd, domain_name, path)\n","\n","    def login(self):\n","        try:\n","            response = self.api.login()\n","            assert response.status_code == 200\n","            logger.info(f'login success, {self.usr}')\n","        except Exception as e:\n","            logger.warning(f'login error, {type(e).__name__}-{e}')\n","\n","    def set_keyword(self, keyword):\n","        try:\n","            self.keyword = str(keyword)\n","            assert isinstance(self.keyword, str)\n","            logger.info(f'set keyword to {self.keyword}')\n","\n","        except Exception as e:\n","            logger.warning(f'set keyword error, {type(e).__name__}-{e}')\n","\n","    def set_simplify(self, simplify):\n","        try:\n","            self.simplify = bool(simplify)\n","            logger.info(f'set simplify to {self.simplify}')\n","\n","        except Exception as e:\n","            logger.warning(f'set simplify error, {type(e).__name__}-{e}')\n","\n","    def search(self, novel_type = 0, order_method = 1):\n","        try:\n","            response = self.api.search(self.keyword, novel_type, order_method)\n","            assert response.status_code == 200\n","            logger.info(f'search success, {self.keyword}')\n","            return response\n","        except Exception as e:\n","            logger.warning(f'search error, {type(e).__name__}-{e}')\n","\n","    def print_novels(self):\n","        try:\n","            print('novels are as follows:')\n","            for index, novel in enumerate(self.novels):\n","                print(f'{index + 1 :<4} : {novel}')\n","            print(f'altogether, there are {len(self.novels)} novels.')\n","\n","        except Exception as e:\n","            logger.warning(f'print novels error, {type(e).__name__}-{e}')\n","\n","    def get_web_novels(self):\n","        try:\n","            self.novels.clear()\n","            novel_type, order_method = 0, 1\n","            response = self.search(novel_type, order_method)\n","            assert response.status_code == 200\n","\n","            current_page = 1\n","            soup = BeautifulSoup(response.text, 'html.parser')\n","            script = soup.find_all('script')[-2].text\n","            match = re.search(r\"total:\\s(\\d+),\", script)\n","            if match:\n","                total_pages = int(match.group(1))\n","\n","            while True:\n","                novel_list = soup.find_all('div', class_ = 'card-body')\n","                for novel in novel_list:\n","                    url = novel.find('a')['href']\n","                    bookname = novel.find('h5', class_ = 'card-title').text.strip()\n","                    author = novel.find('div', class_ = 'card-author').text.strip()\n","                    self.novels.append(Novel(url, bookname, author))\n","\n","                current_page += 1\n","                if current_page > total_pages:\n","                    break\n","\n","                next_page_url = f'/tags-{novel_type}{order_method}/{self.keyword}/{current_page}.html'\n","                response = self.api.open(next_page_url)\n","                assert response.status_code == 200\n","                soup = BeautifulSoup(response.text, 'html.parser')\n","\n","                logger.info(f'get page success, next page url : {next_page_url}')\n","\n","            logger.info(f'get novels success, {len(self.novels)} novels')\n","\n","        except Exception as e:\n","            logger.warning(f'get novels error, {type(e).__name__}-{e}')\n","\n","    def get_local_novels(self, filter = False):\n","        try:\n","            self.novels.clear()\n","            for bookname in os.listdir(self.path):\n","                novel = Novel('', '', '')\n","                novel.load(f'{self.path}/{bookname}/{bookname}.pkl')\n","                if filter:\n","                    detail = novel.bookname + novel.author + novel.introduction + ''.join(novel.tags)\n","                    match = re.search(self.keyword, detail)\n","                    if match:\n","                        self.novels.append(novel)\n","                else:\n","                    self.novels.append(novel)\n","\n","            logger.info(f'get local novels success, {len(self.novels)} novels')\n","\n","        except Exception as e:\n","            logger.warning(f'get local novels error, {type(e).__name__}-{e}')\n","\n","    def update_novels(self):\n","        try:\n","            if self.novels == []:\n","                logger.warning('novels is empty')\n","                return\n","\n","            with ThreadPoolExecutor(max_workers = 50) as executor:\n","                executor.map(self.__update_helper, self.novels)\n","\n","            logger.info(f'update novels success, {len(self.novels)} novels')\n","\n","        except Exception as e:\n","            logger.warning(f'update novels error, {type(e).__name__}-{e}')\n","\n","    def update_1_novel(self):\n","        try:\n","            if self.novels == []:\n","                logger.warning('novels is empty')\n","                return\n","\n","            self.print_novels()\n","\n","            seleted = int(input('select novel to update : '))\n","            while seleted < 1 or seleted > len(self.novels):\n","                print('invalid input')\n","                seleted = int(input('select novel to update : '))\n","\n","            novel = self.novels[seleted - 1]\n","            self.__update_helper(novel)\n","\n","        except Exception as e:\n","            logger.warning(f'update 1 novel error, {type(e).__name__}-{e}')\n","\n","    def __update_helper(self, novel):\n","        try:\n","            response = self.api.open(novel.url)\n","            assert response.status_code == 200\n","            soup = BeautifulSoup(response.text, 'html.parser')\n","\n","            last_update = soup.find('strong', string = '更新日期:').parent.text\n","            match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', last_update)\n","            if match:\n","                last_update = match.group(1)\n","\n","            if last_update != novel.last_update:\n","                novel.last_update = last_update\n","                novel.introduction = soup.find('div', class_ = 'description').text.strip()\n","                novel.tags = [tag.text for tag in soup.find_all('a', class_ = 'tag')]\n","                chapterList = soup.find_all('a', {'data-title' : re.compile(r'.+')})\n","\n","                for index, chapter in enumerate(chapterList):\n","                    title = chapter['data-title']\n","                    url = chapter['href']\n","                    novel.chapters.loc[index] = [index, title, url]\n","\n","                self.download_novels(novel)\n","\n","                logger.info(f'update novel success, {novel}')\n","\n","            else:\n","                logger.info(f'novel not updated, {novel}')\n","\n","        except Exception as e:\n","            logger.warning(f'update helper error, {novel} : {type(e).__name__}-{e}')\n","\n","    def download_novels(self, novel):\n","        try:\n","            for index in range(len(novel.chapters)):\n","                title = f'第 {index + 1} 章 - {novel.chapters.loc[index, \"title\"]}\\n'\n","                novel.text.append(title)\n","\n","                response = self.api.direct_open(novel.chapters.loc[index, 'url'])\n","                assert response.status_code == 200\n","                soup = BeautifulSoup(response.text, 'html.parser')\n","                passages = soup.find('div', class_ = re.compile(r'forum'))\n","\n","                if passages is None:\n","                    continue\n","                else:\n","                    passages = passages.find_all('p', string = re.compile(r'.+'))\n","\n","                for p in passages:\n","                    novel.text.append(p.text)\n","\n","                logger.info(f'download chapter success, {novel.bookname} : {title[:-1]}')\n","\n","            novel.save(self.path, self.simplify)\n","\n","        except Exception as e:\n","            logger.warning(f'download novels error, {type(e).__name__}-{e}')\n","\n","    def save_novels(self):\n","        try:\n","            for novel in self.novels:\n","                novel.save(self.path)\n","                logger.info(f'save novel success, {novel}')\n","\n","        except Exception as e:\n","            logger.warning(f'save novels error, {type(e).__name__}-{e}')"]},{"cell_type":"markdown","metadata":{"id":"LV1HNR7xg4id"},"source":["---\n","### 小说类\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mvji7213dunl"},"outputs":[],"source":["class Novel():\n","    def __init__(self, url, bookname, author):\n","        self.url = url\n","        self.bookname = bookname\n","        self.author = author\n","        self.last_update = ''\n","        self.introduction = ''\n","        self.tags = []\n","        self.chapters = pd.DataFrame(columns = ['index', 'title', 'url'])\n","        self.text = []\n","\n","    def __str__(self):\n","        return f'{self.bookname} - {self.author}'\n","\n","    def load(self, path):\n","        try:\n","            with open(path, 'rb') as f:\n","                novel = pickle.load(f)\n","                self.__dict__.update(novel.__dict__)\n","\n","        except Exception as e:\n","            logger.warning(f'load novel error, {type(e).__name__}-{e}')\n","\n","    def save(self, path, simplify = False):\n","        try:\n","            os.makedirs(f'{path}/{self.bookname}', exist_ok = True)\n","\n","            with open(f'{path}/{self.bookname}/{self.bookname}.pkl', 'wb') as f:\n","                pickle.dump(self, f)\n","\n","            with open(f'{path}/{self.bookname}/{self.bookname}.txt', 'w', encoding = 'utf-8') as f:\n","                f.write(self.bookname + '\\n')\n","                f.write(self.author + '\\n')\n","                f.write(self.introduction + '\\n')\n","                f.write('\\n'.join(self.text))\n","\n","            if simplify:\n","                with open(f'{path}/{self.bookname}/{self.bookname}.txt', 'r', encoding = 'utf-8') as f:\n","                    text = f.read()\n","                    cc = OpenCC('t2s')\n","                    simplified_text = cc.convert(text)\n","                    with open(f'{path}/{self.bookname}/{self.bookname}（简中）.txt', 'w', encoding = 'utf-8') as f:\n","                        f.write(simplified_text)\n","\n","            logger.info(f'save novel success, {self}')\n","\n","        except Exception as e:\n","            logger.warning(f'save novel error, {type(e).__name__}-{e}')"]},{"cell_type":"markdown","metadata":{"id":"wV4WB1rti9Kt"},"source":["---\n","### 接口类\n","\n","主要完成获取 response 的功能"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JuvbXZIYJhMb"},"outputs":[],"source":["class Interface():\n","    def __init__(self, usr, pwd, domain_name):\n","        self.usr = usr\n","        self.pwd = pwd\n","        self.domain_name = domain_name\n","        self.session = requests.Session()\n","        adapter = requests.adapters.HTTPAdapter(pool_connections = 100, pool_maxsize = 100)\n","        self.session.mount('http://', adapter)\n","        self.session.mount('https://', adapter)\n","        self.headers = {\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',\n","        }\n","\n","    def __post(self, url, data, retries = 3):\n","        for i in range(retries):\n","            try:\n","                response = self.session.post(url, data = data, headers = self.headers)\n","                response.encoding = response.apparent_encoding\n","                response.raise_for_status()\n","                return response\n","            except Exception as e:\n","                logger.warning(f'requests post error on attempt {i + 1}, {type(e).__name__}-{e}')\n","                time.sleep(1)\n","\n","    def __get(self, url, retries = 3):\n","        for i in range(retries):\n","            try:\n","                response = self.session.get(url, headers = self.headers)\n","                response.encoding = response.apparent_encoding\n","                response.raise_for_status()\n","                return response\n","            except Exception as e:\n","                logger.warning(f'requests get error on attempt {i + 1}, {type(e).__name__}-{e}')\n","                time.sleep(1)\n","\n","    def login(self):\n","        url = f'{self.domain_name}inc/mem_login.php'\n","        data = {\n","            'email': self.usr,\n","            'pwd': self.pwd,\n","            'remember_me' : 'on'\n","        }\n","        return self.__post(url, data)\n","\n","    def search(self, keyword, novel_type, order_method):\n","        url = f'{self.domain_name}tags-{novel_type}{order_method}/{keyword}/'\n","        return self.__get(url)\n","\n","    def open(self, url):\n","        url = f'{self.domain_name}{url}'\n","        return self.__get(url)\n","\n","    def direct_open(self, url):\n","        return self.__get(url)"]},{"cell_type":"markdown","metadata":{"id":"n30T6IVrt_Ik"},"source":["---\n","### 实例化\n","\n","***使用方法：***\n","* Step1: 使用 **usr, pwd, domain_name, path** 实例化一个 Scraper 对象\n","\n","|<font size='3'>变量名</font>|<font size='4'>含义</font>|\n","|---|---|\n","|<font size='3'>usr</font>|<font size='3'>你的用户名（ESJ是邮箱登录）</font>|\n","|<font size='3'>pwd</font>|<font size='3'>你的密码</font>|\n","|<font size='3'>domain_name</font>|<font size='3'>ESJ网站域名（https://www.esjzone.cc/）</font>|\n","|<font size='3'>path</font>|<font size='3'>爬取的数据保存地址</font>|\n","\n","* Step2: 调用 ***scraper.set_keyword()*** 方法指定搜索关键词（不指定的情况下默认全部）\n","\n","* Step3: *（可选）*调用 ***scraper.set_simplify()*** 方法来指定是否自动下载简中副本\n","\n","* Step4: 调用 ***scraper.get_web_novels()*** 或者 ***scraper.get_local_novels()*** 获得小说列表\n","\n","* Step5: *（可选）*调用 ***print_novels*** 查看现在爬虫获取的轻小说列表\n","\n","(***scraper.get_local_novels()*** 可以指定参数 **filter** 来决定是否使用关键词对本地小说进行筛选)\n","\n","* Step6: 调用 ***scraper.update_novels()*** 或 ***scraper.update_1_novel()*** 来对列表中全部小说或者指定小说进行更新\n","\n","* Step7: 如果使用 **Colab** 运行此程序，可以从左侧的文件中自行下载需要的文件或者自行搭载 **Google Drive** 保存文件  "]},{"cell_type":"markdown","metadata":{"id":"0nKwZl_D72f1"},"source":["以下是一个简单的实例:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fs8Nl41wDrAP"},"outputs":[],"source":["usr = 'your_username'\n","pwd = 'your_password'\n","domain_name = 'https://www.esjzone.cc/'\n","path = 'novels'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OBcMngiHHz9"},"outputs":[],"source":["os.makedirs(path, exist_ok = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2490,"status":"ok","timestamp":1724045888693,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"4Ag-6aDBy7go","outputId":"29a5b4d4-ca62-4ece-d0af-67d1d677933f"},"outputs":[],"source":["scraper = Scraper(usr, pwd, domain_name, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1724045888693,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"oUv-4CqhuHkn","outputId":"e2d78ed9-356e-4a8b-f287-537565ff651a"},"outputs":[],"source":["scraper.set_keyword('keyword')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1724045888693,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"EDqbPF1OCorl","outputId":"5addf7ea-3ad5-49f3-cdfd-6e94611a2671"},"outputs":[],"source":["scraper.set_simplify(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26521,"status":"ok","timestamp":1724045915212,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"cLSxZA7kue40","outputId":"d12243db-23c0-4818-d029-c678a6371cab"},"outputs":[],"source":["scraper.get_web_novels()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1724045915212,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"lkLSLz9IFh_U","outputId":"05384d21-72df-4b7e-a392-64e4522e94b1"},"outputs":[],"source":["scraper.print_novels()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149750,"status":"ok","timestamp":1724046064958,"user":{"displayName":"Poi Hakurei","userId":"12599745068401382907"},"user_tz":-480},"id":"REhvlhKCF2ge","outputId":"bc5d721c-0755-421b-f870-11af9bd9e384"},"outputs":[],"source":["scraper.update_1_novel()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPiuwfkn4+Pp1jGvewfiIk7","collapsed_sections":["2S_GYBtxKapL","RTN2GVFocTSm","LV1HNR7xg4id","wV4WB1rti9Kt"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
